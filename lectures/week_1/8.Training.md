# Training

- For now we will ignore validation and testing
- Initialize model parameters theta (could be random, zero, or other strategy)
- While i < max_epochs (pass over the entire data-set):
    - computer gradient for each parameter using training set
    - Use gradient descent learning rule to update parameters
- How does final model perform?
    - Evaluating on training data is a poor representation

* We could also look at minimizing the loss function as opposed to a maximum number of passes*